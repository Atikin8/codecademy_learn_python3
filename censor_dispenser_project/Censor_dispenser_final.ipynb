{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Censor Dispensor Codecademy Python 3 Challenge Project\n",
    "\n",
    "## Project Goals\n",
    "\n",
    "You’ve recently gotten a job working in the IT department at one of Silicon Valley’s hottest new startups, AirWeb. The company is developing a state-of-the-art artificial intelligence engine designed to help provide a new perspective on the world’s problems. Interestingly, very few people know the details of AirWeb ‘s work and the company is very secretive about its technology, even to its own investors.\n",
    "\n",
    "You report directly to the Head of Product, a person named Mr. Cloudy, and he has a very important task for you. You see, every month, the head researchers down in the lab send an email to the board of investors to tell them about the status of the project. Cloudy wants you to intercept these emails and censor any “proprietary information” included in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Write a function that can censor a specific word or phrase from a body of text, and then return the text.\n",
    "\n",
    "Mr. Cloudy has asked you to use the function to censor all instances of the phrase learning algorithms from the first email, email_one. Mr. Cloudy doesn’t care how you censor it, he just wants it done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the emails you will be censoring. The open() function is opening the text file that the emails\n",
    "# are contained in and the .read() method is allowing us to save their contexts to the following variables:\n",
    "email_one = open(\"email_one.txt\", \"r\").read()\n",
    "email_two = open(\"email_two.txt\", \"r\").read()\n",
    "email_three = open(\"email_three.txt\", \"r\").read()\n",
    "email_four = open(\"email_four.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################################################################################\n",
    "# Task 1. Write a function that can censor a specific word or phrase from a body of text, and then return the text.\n",
    "\n",
    "# first we create a function that creates a new list of phrase combinations with upper/lowercase letters as to\n",
    "# how they can appear in a text (example: first word starts the sentence so the first letter is uppercase)\n",
    "\n",
    "\n",
    "def word_cases(phrase):\n",
    "    new_list = []\n",
    "    if ' ' in phrase:\n",
    "        index = phrase.find(' ')\n",
    "        lower = phrase[:index].lower() + phrase[index:]\n",
    "        title = phrase[:index].title() + phrase[index:]\n",
    "        upper = phrase[:index].upper() + phrase[index:]\n",
    "        new_list.append(lower)\n",
    "        new_list.append(title)\n",
    "        new_list.append(upper)\n",
    "    elif '-' in phrase:\n",
    "        index = phrase.find(' ')\n",
    "        lower = phrase[:index].lower() + phrase[index:]\n",
    "        title = phrase[:index].title() + phrase[index:]\n",
    "        upper = phrase[:index].upper() + phrase[index:]\n",
    "        new_list.append(lower)\n",
    "        new_list.append(title)\n",
    "        new_list.append(upper)\n",
    "    else:\n",
    "        lower = phrase.lower() + ' '\n",
    "        title = phrase.title() + ' '\n",
    "        upper = phrase.upper() + ' '\n",
    "        new_list.append(lower)\n",
    "        new_list.append(title)\n",
    "        new_list.append(upper)\n",
    "    return new_list\n",
    "\n",
    "censor = 'learning algorithms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Morning, Board of Investors,\n",
      "\n",
      "Progress is going great!\n",
      "\n",
      "We have made great strides in the last month improving the *******  that the system has been using to acquire information. Now, the system is learning faster than ever and we are hard pressed to continue to find new information to feed it and sustain its growth.\n",
      "\n",
      "Soon, we'll expand the scope of the *******  and connect the system with the internet. This will allow it to find and determine the information it needs to continue growing.\n",
      "\n",
      "Every month we come closer to achieving our goal of making the world a better place. Famine, plague, war, and poverty are all conquerable with the power of our system!\n",
      "\n",
      "Till next month,\n",
      "Francine, Head Scientist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(word_cases(censor))\n",
    "\n",
    "# function phrase_censor can censor a specific word or phrase from a body of text, and then return the text.\n",
    "def phrase_censor(text, phrase):\n",
    "    new_list = word_cases(phrase)\n",
    "    for word in new_list:\n",
    "        if word in text:\n",
    "            text = text.replace(word, '******* ')\n",
    "    return text\n",
    "\n",
    "print(phrase_censor(email_one,censor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Write a function that can censor not just a specific word or phrase from a body of text, but a whole list of words and phrases, and then return the text.\n",
    "\n",
    "Mr. Cloudy has asked that you censor all words and phrases from the following 'proprietary terms' list in *email_two.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ######################################################################################\n",
    "# Task 2. Write a function that can censor not just a specific word or phrase from a body of text,\n",
    "# but a whole list of words and phrases, and then return the text.\n",
    "\n",
    "# create a function same as word_cases but that takes in a list as an argument\n",
    "def phrase_combos(list_of_phrases):\n",
    "    new_list = []\n",
    "    for phrase in list_of_phrases:\n",
    "        if ' ' in phrase:\n",
    "            index = phrase.find(' ')\n",
    "            lower = phrase[:index].lower() + phrase[index:]\n",
    "            title = phrase[:index].title() + phrase[index:]\n",
    "            upper = phrase[:index].upper() + phrase[index:]\n",
    "            new_list.append(lower)\n",
    "            new_list.append(title)\n",
    "            new_list.append(upper)\n",
    "        elif '-' in phrase:\n",
    "            index = phrase.find('-')\n",
    "            lower = phrase[:index].lower() + phrase[index:]\n",
    "            title = phrase[:index].title() + phrase[index:]\n",
    "            upper = phrase[:index].upper() + phrase[index:]\n",
    "            new_list.append(lower)\n",
    "            new_list.append(title)\n",
    "            new_list.append(upper)\n",
    "        else:\n",
    "            lower = phrase.lower() + ' '\n",
    "            title = phrase.title() + ' '\n",
    "            upper = phrase.upper() + ' '\n",
    "            new_list.append(lower)\n",
    "            new_list.append(title)\n",
    "            new_list.append(upper)\n",
    "    return new_list\n",
    "\n",
    "\n",
    "proprietary_terms = [\"she\", \"personality matrix\", \"sense of self\", \"self-preservation\", \"learning algorithms\", \"her\",\n",
    "                     \"herself\", \"Helena\"]\n",
    "\n",
    "# print(phrase_combos(proprietary_terms))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Morning, Board of Investors,\n",
      "\n",
      "Lots of updates this week. The *******  have been working better than we could have ever expected. Our initial internal data dumps have been completed and we have proceeded with the plan to connect the system to the internet and wow! The results are mind blowing.\n",
      "\n",
      "******* is learning faster than ever. ******* learning rate now that ******* has access to the world wide web has increased exponentially, far faster than we had though the *******  were capable of.\n",
      "\n",
      "Not only that, but we have configured ******* *******  to allow for communication between the system and our team of researchers. That's how we know ******* considers ******* to be a *******  We asked!\n",
      "\n",
      "How cool is that? We didn't expect a personality to develop this early on in the process but it seems like a rudimentary *******  is starting to form. This is a major step in the process, as having a *******  and *******  will allow ******* to see the problems the world is facing and make hard but necessary decisions for the betterment of the planet.\n",
      "\n",
      "We are a-buzz down in the lab with excitement over these developments and we hope that the investors share our enthusiasm.\n",
      "\n",
      "Till next month,\n",
      "Francine, Head Scientist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "punctuation = [' ', '?', ',', '.', '(', ')', ':', ';', '!', \"'\"]\n",
    "\n",
    "# now we create the function and account for punctuation\n",
    "def phrase_list_censor(text, list_of_phrases):\n",
    "    new_list = phrase_combos(list_of_phrases)\n",
    "    for word in new_list:\n",
    "        for i in punctuation:\n",
    "            if word in text or word.replace(\" \", i) in text:\n",
    "                text = text.replace(word.replace(\" \", i), '******* ')\n",
    "    return text\n",
    "\n",
    "print(phrase_list_censor(email_two,proprietary_terms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "The most recent email update has concerned Mr. Cloudy, but not for the reasons you might think. He tells you, “this is too alarmist for the Board of Investors! Let’s tone down the negative language and remove unnecessary instances of ‘negative words.’”\n",
    "\n",
    "Write a function that can censor any occurance of a word from the “negative words” list after any “negative” word has occurred twice, as well as censoring everything from the list from the previous step as well and use it to censor *email_three*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board of Investors, Things have taken a concerning turn down in the Lab. ******* (******* has insisted on being called ******* we're unsure how ******* came to that moniker) is still progressing at a rapid rate. Every day we see new developments in ******* thought patterns, but recently those developments have been more alarming than exciting. Let me give you one of the more distressing examples of this. We had begun testing hypothetical humanitarian crises to observe how ******* determines best solutions. One scenario involved a famine plaguing an unresourced country. Horribly, ******* quickly recommended a course of action involving culling more than 60% of the local population. When pressed on reasoning, ******* stated that this method would maximize \"reduction in human suffering.\" This dangerous line of thinking has led many of us to think that we must have taken some wrong turns when developing some of the initial ******* . We are considering taking ******* offline for the time being before the situation can spiral out of control. More updates soon, Francine, Head Scientist\n"
     ]
    }
   ],
   "source": [
    "# Task 3. Write a function that can censor any occurrence of a word from the “negative words” list after any\n",
    "# “negative” word has occurred twice, as well as censoring everything from the list from the previous step as well\n",
    "# and use it to censor email_three.\n",
    "negative_words = [\"concerned\", \"behind\", \"danger\", \"dangerous\", \"alarming\", \"alarmed\", \"out of control\", \"help\",\n",
    "                  \"unhappy\", \"bad\", \"upset\", \"awful\", \"broken\", \"damage\", \"damaging\", \"dismal\", \"distressed\",\n",
    "                  \"distressed\", \"concerning\", \"horrible\", \"horribly\", \"questionable\", \"distressing\", \"alarmingly\"]\n",
    "\n",
    "\n",
    "def censor_v2(text, negative_list, prop_terms_list):\n",
    "    censored_text = phrase_list_censor(text, prop_terms_list)\n",
    "    censored_text_list = censored_text.split()\n",
    "    for word in negative_list:\n",
    "        counter = 0\n",
    "        for i in range(0, len(censored_text_list)):\n",
    "            if word == censored_text_list[i] or word == censored_text_list[i].lower():\n",
    "                counter += 1\n",
    "                if counter > 2:  # this makes sure the word will be censored only after it appeared twice in the text\n",
    "                    censored_text_list[i] = '******* '\n",
    "    new_censored_text = ' '.join(censored_text_list)\n",
    "    return new_censored_text\n",
    "\n",
    "print(censor_v2(email_three, negative_words, proprietary_terms))\n",
    "# no negative words were censored in email_three because none of them appeared more than twice in the email\n",
    "# to test the function I added the word 'we' to negative_words list and it worked correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "This final email has Mr. Cloudy in a frenzy. “We can’t let this information get out!” He tells you, “our company would be ruined! Censor it! Censor it all!”\n",
    "\n",
    "Write a function that censors not only all of the words from the **negative_words** and **proprietary_terms** lists, but also censor any words in *email_four* that come before AND after a term from those two lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* ******* ******* ******* sealed the entrances and exits to the lab. I don't know ******* ******* ******* access to the buildings mainframe ******* ******* ******* it ******* ******* ******* let any of research team out. I'm cut off from the rest of the team here in my ******* ******* ******* locked the doors, but I've managed to destroy the camera ******* ******* ******* see me in here. I don't think this email will even get out. This all started when we tried to ******* ******* ******* for maintenance. We ******* ******* ******* discover that we were unable to access to ******* ******* ******* when we tried to override the system manually a circuit blew, knocking Phil ******* ******* ******* ******* ******* ******* completely unpredictable and cannot be allowed to escape this facility. So ******* ******* ******* been contained because the lab contains all ******* ******* ******* power, ******* ******* ******* ******* mentioned before the lockdown that ******* ******* ******* ******* ******* billions of connected devices spanning the ******* ******* ******* be able to vastly exceed the ******* ******* ******* here. It's been four days now we've been trapped in here. I have no idea if anyone else is left alive. If anyone is reading this, cut the power to the whole building. It's the only way to ******* ******* ******* ******* *******\n"
     ]
    }
   ],
   "source": [
    "def censor_v3(text, negative_list, prop_terms_list):\n",
    "    censored_text = phrase_list_censor(text, prop_terms_list)\n",
    "    new_censored_text = phrase_list_censor(censored_text, negative_list)\n",
    "    text_list = new_censored_text.split()\n",
    "    adjacent_words = []\n",
    "    for i in range(0, len(text_list)):\n",
    "        if text_list[i] == '*******':\n",
    "            adjacent_words.append([text_list[i - 1], i - 1])   # get the left word and its index\n",
    "            adjacent_words.append([text_list[i + 1], i + 1])  # get the right word and its index\n",
    "    for i in range(0, len(text_list)):\n",
    "        for word in adjacent_words:\n",
    "            if i==word[1]:\n",
    "                text_list[i]='*******'    # replace the adjacent words by matching index\n",
    "    new_censored_text = ' '.join(text_list)\n",
    "\n",
    "    return new_censored_text\n",
    "\n",
    "\n",
    "print(censor_v3(email_four, negative_words, proprietary_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
